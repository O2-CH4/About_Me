# About Me


## 1) Overview:

- Canadian AI Graduate Student 
- Currently following 2 courses in Montreal: Quantum Computing and Theoretical Principles of Deep Learning. 
- Student with interdisciplinary interests that is strongly driven to understand complex problems and create utility for others.






## 2) Interests:

- Applying new tools from AI/Statistics to problems in Science & Engineering. 




## 3) Repository for Diverse Projects/Files:


### • [Theory behind ML Models + Code Implementations](link:____) (Summer 2021)  

- Took 1 month of my summer to create an 80 pages documents on all the main Machine Learning Models (Theory + Code)
- The content was extracted from 20 books and multiple papers/blogs (Used Jupiter Notebooks and Python)
- Eventually served many friends looking to prepare themselves for the graduate ML course
- Also did a similar small document on the topic of Mathematical Modeling in order to introduce myself to some Julia implementations


### • [Critical Temperature Prediction for Superconducting Materials](link:____) (Fall 2021)

- **Context**: Graduate ML Course
- **Overview**: Project article on a data-driven approach for critical temperature (Tc) prediction of superconducting materials. 
- **Details**: Deep Neural Network models were used as surrogate models to learn the mapping between the features of known superconducting materials and their respective critical temperature (Tc) observed in laboratory.  A dataset of 21 263 superconductors was used with 82 attributes per superconductor, including characteristics of the materials such as the number of elements that compose them, their average atomic weights and the entropy of their atomic masses.



### • [Neural Combinatorial Solver Project (WTA Deep-RL)](link:____) (Winter 2022)

- **Context**: Combinatorial Optimization Graduate course 
- **Overview**: Me and two other students realized a project relating the trade-offs made when using end-to-end neural solvers instead of traditional solving methods for combinatorial optimization problems. 
- **Details**: Neural Solvers approximate/learn an end-to-end policy that take a problem instance as input and output directly a solution to our problem that ideally optimize a desired objective function(s) and respect a set of constraints.  Problems can be Permutation or Assignment-based. Famous examples are the Traveling Salesman Problem (TSP) or any type of resource allocation optimization problem. In our work, we focused on comparing the results of a state-of-the-art Graph Neural Network architecture and a traditional solver on a specific assignment problem: The Weapon-Target Assignment (WTA). This defense-related problem seeks to assign interceptor (or missiles) from different weapon systems to targets in order to minimize the total expected destructive value of those incoming targets.  This situation is analogous to the real problem of allocating a finite set of different type of Anti-Ballistic Interceptors (Endo/Exo) to an incoming swarm of MIRVs with Re-Entry vehicles maneuvering in the atmosphere at hypersonic speeds coming towards key communication, energetic & military infrastructures. In short, we used reinforcement learning to parametrize our neural solver in order to learn an optimal policy, where the reward was the negative of the total expected destructive value of all targets after an assignment. Finally, solutions were generated autoregressively by our model at inference time. Despite being time-constrained for this project, we demonstrated results related to the speed-optimality trade-offs between those two methods and discussed different uses cases where one may be better suited than the other.


...


